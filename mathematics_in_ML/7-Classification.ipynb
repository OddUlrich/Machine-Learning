{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMP3670 Assignment 7 - Classification**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enter Your Student ID:** u6726234\n",
    "\n",
    "**Your Name:** Wyman Wong\n",
    "    \n",
    "**Deadline:** 16:00pm, November 1st, 2019 (can be extended to 23:59pm, November 3rd, 2019)\n",
    "\n",
    "**Submit:** Write your answers in this file, and submit a single Jupyter Notebook file (.ipynb) on Wattle. Rename this file with your student number as 'uXXXXXXX.ipynb'.\n",
    "    \n",
    "**Enter Discussion Partner IDs Below:**\n",
    "- None\n",
    "\n",
    "**Programming Section** (100%)\n",
    "- 1.1 = 5%\n",
    "- 1.2 = 5%\n",
    "- 1.3 = 10%\n",
    "- 1.4 = 15%\n",
    "- 1.5 = 5%\n",
    "- 1.6 = 10%\n",
    "- 2.1 = 50%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THEORY SECTION (0%)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no theory questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "**PROGRAMMING SECTION (100%)**\n",
    "---\n",
    "\n",
    "For all of the following, program the solution yourself. Don't just call a library function that does the whole question for you, or you'll get zero (no, that doesn't mean you can't use any library functions, but it does mean that you have to show you understand how to compute the answer yourself).\n",
    "\n",
    "**All written answers** should be between 50 and 500 words. If you can describe all the necessary information in 50 words, that's better. However, you'll only be graded on whether you describe the necessary ideas.\n",
    "\n",
    "\n",
    "-----------\n",
    "\n",
    "   **TASK 0.1:** You know the drill. Import Numpy and PyPlot. We're also going to generate a dataset.\n",
    "\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 0. ... 1. 1. 0.]\n",
      " [0. 1. 1. ... 1. 0. 0.]\n",
      " [1. 1. 0. ... 0. 1. 1.]\n",
      " ...\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 0. 1. ... 0. 1. 1.]\n",
      " [1. 1. 1. ... 1. 0. 0.]]\n",
      "[[0. 1. 0. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 1. 1.]\n",
      " [0. 1. 0. 1.]\n",
      " [1. 1. 0. 0.]]\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D #This is for 3d scatter plots.\n",
    "import math\n",
    "import random\n",
    "from scipy.stats import multivariate_normal\n",
    "import os\n",
    "from matplotlib.pyplot import imread\n",
    "np.random.seed(13579201)\n",
    "\n",
    "k = 4\n",
    "n = 8\n",
    "m = 5000\n",
    "D = np.zeros((m, n))\n",
    "Y = np.zeros((m, k))\n",
    "for ix in range(0, m):\n",
    "    dpool = random.randint(0, 2**n)\n",
    "    ypool = round(np.sqrt(dpool))\n",
    "    for iy in range(n):\n",
    "        if dpool >= 2**(D.shape[1] - iy - 1):\n",
    "            D[ix, iy] = 1\n",
    "            dpool -= 2**(D.shape[1] - iy - 1)\n",
    "    for iy in range(Y.shape[1]):\n",
    "        if ypool >= 2**(Y.shape[1] - iy - 1):\n",
    "            reading = ((np.random.randn() + 0.3) > 0)\n",
    "            Y[ix, iy - k] = 1 * reading\n",
    "            ypool -= 2**(Y.shape[1] - iy - 1)\n",
    "\n",
    "print(D)\n",
    "print(Y)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROGRAMMING EXERCISE 1  \n",
    "-----------\n",
    "\n",
    "Note that for all of the questions that follow, you may re-use any code from your previous assignments.\n",
    "\n",
    "We're going to implement logistic regression with gradient descent in this first exercise.\n",
    "\n",
    "It's much like linear regression, but we apply a sigmoid function to the output, which of course changes the gradient!\n",
    "\n",
    "The point of logistic regression is to predict a label {0, 1} or a probability.\n",
    "\n",
    "We're going to re-use the dataset from assignment 5 for this problem:\n",
    "\n",
    "$D \\in \\mathbb{R}^{m \\times n}$ together with $Y \\in \\mathbb{R}^{m \\times k}$ is our dataset.\n",
    "\n",
    "Our objective is to predict $Y$ given $D$, such that $s(D\\theta) = Y$, where $s()$ is the same logistic or sigmoid function you used in assignment 4.\n",
    "\n",
    "We're going to use logistic regression to predict a binary string!\n",
    "\n",
    "\n",
    "---\n",
    "   **TASK 1.1:** Complete the function $initialise(D, Y) = \\theta$, which detects the dimensions of $D$ and $Y$ and generates $\\theta$ of appropriate dimension, with random values appropriate for regression, such that the dimensions of $D\\theta$ is the same as the dimensions of $Y$.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.70002750e-01 5.96396786e-01 9.94706165e-01 2.51915656e-01]\n",
      " [3.23609147e-01 4.66197664e-04 8.79563579e-01 2.17754432e-01]\n",
      " [2.10284607e-01 9.25795606e-02 1.29214215e-01 5.37951137e-01]\n",
      " [8.65924046e-01 1.82478510e-01 3.99470062e-01 6.71662567e-02]\n",
      " [2.35689568e-01 2.65827481e-01 2.32733916e-01 5.51602149e-01]\n",
      " [7.34482228e-01 5.38155369e-02 1.90173747e-01 3.68688362e-01]\n",
      " [1.51635625e-02 7.78813993e-01 4.46012509e-01 5.64616539e-01]\n",
      " [6.57002650e-01 7.24105193e-02 1.03377975e-02 2.42410825e-01]]\n"
     ]
    }
   ],
   "source": [
    "def initialise(D, Y):\n",
    "    theta = None\n",
    "    #YOUR CODE HERE\n",
    "\n",
    "    n = D.shape[1]\n",
    "    k = Y.shape[1]\n",
    "    \n",
    "    # Small random values.\n",
    "    theta = np.random.rand(n, k)\n",
    "    \n",
    "    return theta\n",
    "\n",
    "theta = initialise(D, Y)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**TASK 1.2:** Complete $s(Z) = sZ$, which accepts a matrix $Z$ and outputs $sZ$, where $sZ$ is just $Z$ with the sigmoid (or \"logistic\") function applied to every element.\n",
    "\n",
    "You must do this without using a loop.\n",
    "\n",
    "**HINT:** \n",
    "- Recall assignment 4, where you applied the sigmoid function in exactly the same manner.\n",
    "- You might want to use np.vectorize(). You'll probably need to define a second function which accepts a single element and applies the sigmoid function to that element (this is how np.vectorize works).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " ...\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "def s(Z):\n",
    "    sZ = None\n",
    "    #YOUR CODE HERE\n",
    "    \n",
    "    vec_sigmoid = np.vectorize(sigmoid)\n",
    "    sZ = vec_sigmoid(Z)\n",
    "\n",
    "    return sZ\n",
    "\n",
    "def sigmoid(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s\n",
    "\n",
    "print((s(D@theta * 999999999)).astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall assignment 4, where you implemented a neural network where the $X\\theta^{[1]}$ had a sigmoid function applied to its output.\n",
    "\n",
    "Thus the first layer was the function $s(X\\theta^{[1]})$.\n",
    "\n",
    "That first layer was performing logistic regression with mean squared error!\n",
    "\n",
    "Now, for what follows you may choose any convex loss function you wish. For instance, you might:\n",
    "\n",
    "1. Implement the mean squared loss function as you did in assignment 4 exercise 2 (this will only get you half marks).\n",
    "2. Implement the cross-entropy loss (this is the most common loss function for logistic regression, and I recommend you implement this).\n",
    "3. Implement anything else your heart desires, so long as it functions as a convex loss function for logistic regression!\n",
    "\n",
    "Not sure what convex is? Then you must look this up. Convex means the loss function has only one global minimum!\n",
    "\n",
    "Likewise with cross entropy loss; you need to research and understand this on your own. \n",
    "\n",
    "Cross entropy loss when $k = 1$ is computed as follows:\n",
    "\n",
    "$\\mathcal{L}(\\theta) = -\\frac{1}{m}\\sum_{i=0}^m \\left[y_i ln (s(d_i\\theta)) + (1 - y_i) ln (1 - s(d_i\\theta))\\right] + \\frac{\\gamma}{2}\\theta^T\\theta$\n",
    "\n",
    "... where $ln(z)$ is the natural logarithm of a scalar $z$.\n",
    "\n",
    "When $k =1$, $s(d_i\\theta)$ and $y_i$ are scalars. As $k > 1$, you'll need to modify the above loss function to work with vectors.\n",
    "\n",
    "---\n",
    "\n",
    "**TASK 1.3:** Complete the function $\\mathcal{L}(\\theta) = loss(D, \\theta, Y) = l$, where $l$ is a scalar that represents the loss. That means $l$ is the sum of the $k$ losses (because we're simultaneously running $k$ regressions again).\n",
    "\n",
    "You will get 50% for implementing the mean squared loss function you used in assignment 4 exercise 2, or 100% for implementing a different loss function (so long as it works).\n",
    "\n",
    "Bear in mind you will need to compute $\\frac{d \\mathcal{L}(\\theta)}{d \\theta}$ for this loss function in order to complete the next question, so pick something you actually know how to compute the derivative of.\n",
    "\n",
    "You must also include a form of regularisation such as $\\gamma \\theta^T \\theta$, where $\\gamma$ is a scalar chosen by you (I suggest something like 0.0001). When computing regularisation, remember that $k > 1$. 20% of your grade will be deducted for failing to implement a form of regularisation.\n",
    "\n",
    "**HINT:** If implementing cross entropy loss, you'll need to account for taking the log of $0$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.168505671754815\n"
     ]
    }
   ],
   "source": [
    "def loss(D, theta, Y):\n",
    "    l = None\n",
    "    #YOUR CODE HERE\n",
    "    \n",
    "    m = Y.shape[0]\n",
    "    \n",
    "    # loss: (k, 1)\n",
    "    loss = np.zeros((Y.shape[1]))\n",
    "    \n",
    "    sZ = s(D@theta) # (m, k)\n",
    "\n",
    "    # Y: (m, k)\n",
    "    loss = -np.mean(Y*np.log(sZ)+(1-Y)*(np.log(1-sZ)), axis=0)\n",
    "    \n",
    "    # Regularized items\n",
    "    garma = 1.0e-4\n",
    "    regularized_item = garma * np.sum(theta*theta, axis=0) / 2 # (k, 1)\n",
    "\n",
    "    loss += regularized_item\n",
    "    l = np.sum(loss)\n",
    "    \n",
    "    return l\n",
    "\n",
    "l = loss(D, theta, Y)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**TASK 1.4:** Implement $gradient\\_update(D, \\theta, Y, \\lambda) = \\theta - \\lambda \\frac{d \\mathcal{L}(\\theta)}{d \\theta} = \\theta_{new}$, which updates $\\theta$ using the gradient of the loss function you implemented above.\n",
    "\n",
    "It must be the gradient of the loss function you implemented, not a different loss function.\n",
    "\n",
    "$\\lambda$ is the learning rate.\n",
    "\n",
    "As above, if it's just the mean squared loss you will only be eligible for 50% of the grade, and 20% of your grade will be deducted for not including a form of regularisation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.65237024e-01  5.91982209e-01  9.82227235e-01  2.41239665e-01]\n",
      " [ 3.18289930e-01 -9.92356011e-03  8.69771898e-01  2.07809219e-01]\n",
      " [ 2.02246766e-01  8.51089289e-02  1.20037983e-01  5.27842908e-01]\n",
      " [ 8.56771669e-01  1.74726192e-01  3.87236029e-01  5.78028176e-02]\n",
      " [ 2.27543143e-01  2.57326361e-01  2.20953699e-01  5.39678528e-01]\n",
      " [ 7.25339291e-01  4.63194384e-02  1.78640468e-01  3.57110023e-01]\n",
      " [ 7.41591972e-03  7.69492950e-01  4.34177567e-01  5.52462525e-01]\n",
      " [ 6.47796822e-01  6.42752982e-02 -5.35575940e-04  2.30829471e-01]]\n"
     ]
    }
   ],
   "source": [
    "def gradient_update(D, theta, Y, lam):\n",
    "    theta_new = None\n",
    "    #YOUR CODE HERE\n",
    "    \n",
    "    m = D.shape[0]\n",
    "    \n",
    "    # Regularized items\n",
    "    garma = 1.0e-4\n",
    "    grad = D.T@(s(D@theta) - Y) / m + garma*theta\n",
    "        \n",
    "    theta_new = theta - lam*grad\n",
    "    \n",
    "    return theta_new\n",
    "\n",
    "theta_new_test = gradient_update(D, theta, Y, 0.05)\n",
    "print(theta_new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**TASK 1.5:** Complete the function $predict(d, \\theta) = s(d\\theta) = y$, where $y \\in \\{0, 1\\}^{(p \\times k)}$ and $d \\in \\{0, 1\\}^{(p \\times n)}$ and $1 \\le p \\le m$.\n",
    "\n",
    "Note, every element of the output must be an integer.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "def predict(d, theta):\n",
    "    y = None\n",
    "    #YOUR CODE HERE\n",
    "    \n",
    "    y = s(d@theta)\n",
    "    \n",
    "    return np.round(y).astype(int)\n",
    "\n",
    "print(predict(D[0:7, :], theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**TASK 1.6:** Complete the function $gradient\\_descent(D, Y, lam, iterations) = \\theta$, which  uses the functions above to find $\\theta$ such that $predict(D, \\theta) = Y$.\n",
    "\n",
    "As in assignment 4, record the loss at each iteration and store the values in the array $losses$.\n",
    "\n",
    "You need to make sure your loss decreases in monotone downward trajectory. If it increases at any point, something has gone wrong.\n",
    "\n",
    "You will be assessed on whether, overall, you've succeeded in implementing logistic regression (not just the gradient descent algorithm, which you've done before in any case).\n",
    "\n",
    "**HINT:** \n",
    "- Remember, at the start of this assignment we said you could re-use your code from previous assignments.\n",
    "- Also, it's impossible to get zero error. You need to just minimise the error.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.74260445  0.9623096  -0.21122392 -0.23234891]\n",
      " [ 0.38476392 -0.7544361   0.35760878  0.06318174]\n",
      " [-0.19692973 -0.04161106  0.34384289  0.19162238]\n",
      " [-0.12360463 -0.14167045 -0.2897868   0.03545272]\n",
      " [-0.16870563 -0.23538782 -0.2508148  -0.04113572]\n",
      " [-0.3409293  -0.00559352 -0.25000796 -0.31181895]\n",
      " [-0.02555657  0.01637888 -0.2130226  -0.21181654]\n",
      " [-0.00765487 -0.32475031 -0.26203803 -0.36709476]]\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent(D, Y, lam, iterations):\n",
    "    theta = initialise(D, Y)\n",
    "    losses = np.zeros((iterations))\n",
    "    #YOUR CODE HERE\n",
    "    for i in range(iterations):\n",
    "        l = loss(D, theta, Y)\n",
    "        losses[i] = l\n",
    "        \n",
    "        theta = gradient_update(D, theta, Y, lam)\n",
    "    \n",
    "    return theta, losses\n",
    "\n",
    "lam = 0.3 #Learning rate\n",
    "iterations = 60 #Number of iterations of gradient descent\n",
    "\n",
    "#For the purposes of doing this assignment, this code isn't really here. Pretend it's engraved in rock.\n",
    "theta, losses = gradient_descent(D, Y, lam, iterations)\n",
    "plt.plot(losses)\n",
    "plt.show()\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROGRAMMING EXERCISE 2\n",
    "---\n",
    "\n",
    "You might remember the linearly inseparable dataset from the clustering assignment. Below, we're re-using it (see D2_temp, and X which is the final dataset), only now the datapoints all come labelled in the matrix $Z$.\n",
    "\n",
    "You're going to try and predict $Z$ given $X$.\n",
    "\n",
    "Look at how the below data is constructed. It is not only linearly inseparable, but $X$ is composed of thousands of irrelevant variables that have no impact on $Z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is (5000, 11854)\n"
     ]
    }
   ],
   "source": [
    "def gen_D2Y2(m):\n",
    "    D2 = np.random.randn(m, 2)\n",
    "    Y2 = np.zeros((m, 2))\n",
    "    for r in range(D2.shape[0]):\n",
    "        s = np.linalg.norm(D2[r, :])\n",
    "        if s > 1.85:\n",
    "            Y2[r, 0] = 1\n",
    "        elif s < 0.3:\n",
    "            Y2[r, 1] = 1\n",
    "    return D2, Y2\n",
    "m2 = 5000\n",
    "D2_temp, Z = gen_D2Y2(m2)\n",
    "colours = ['g', 'b']\n",
    "\n",
    "def allocator(D2, Z, j):\n",
    "    cluster = []\n",
    "    for i in range(D2.shape[0]):\n",
    "        if Z[i, j]:\n",
    "            cluster.append(D2[i, :])\n",
    "    return np.asarray(cluster)\n",
    "for i in range(2):\n",
    "    cluster = allocator(D2_temp, Z, i)\n",
    "    plt.scatter(cluster[:,0], cluster[:,1], c=colours[i])\n",
    "plt.show()\n",
    "\n",
    "left = np.random.randint(0, 10000)\n",
    "right = np.random.randint(0, 10000)\n",
    "X = np.hstack([np.random.randn(m2, left), D2_temp, np.random.randn(m2, right)])\n",
    "print('The shape of X is', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "So, as stated above you must predict $Z$ using only the matrix $X$. \n",
    "\n",
    "You can re-use any of your code from previous assignments. \n",
    "\n",
    "You will need to:\n",
    "1. Understand how $X$ and $Z$ are constructed.\n",
    "2. Train at least 1 model to perform prediction.\n",
    "3. Complete the predict function below such that it can predict $Z$.\n",
    "\n",
    "You will likely need to use all of your knowledge from this course. \n",
    "\n",
    "---\n",
    "\n",
    "**TASK 2.1:** Complete the functions below such that $predict\\_Z(X) = Z\\_prediction$.\n",
    "\n",
    "If you succeed at training a model such that $predict\\_Z(X) = Z\\_prediction$, and the distance between $Z$ and $Z\\_predicton$ is minimised, you will get the marks. \n",
    "\n",
    "You cannot use the variables D2_temp, left, or right. You must predict $Z$ using $X$ by training a model on $X$ and $Z$. \n",
    "\n",
    "You can train any models you wish, or create any additional functions you wish. \n",
    "\n",
    "Unlike every other question in this course, you are also now allowed to use any of the library functions in numpy and, if you wish, scikitlearn.\n",
    "\n",
    "**HINT:**\n",
    "- You can add the parameters your model learns to $predict\\_Z(X)$. No, you cannot add $Z$ as a parameter to $predict\\_Z(X)$.\n",
    "- You can combine models, add dimensions or split the dataset, using your knowledge of how the dataset is constructed.\n",
    "- You can and should re-use any code you've written in previous assignments.\n",
    "- Remember, there are only 2 relevant dimensions of $X$, and these 2 dimensions are hidden somewhere randomly determined.\n",
    "- Depending which models you use, you might need to add an additional dimension to make the data linearly separable (assuming you use something like logistic regression which requires linear separability).\n",
    "- I encourage you to discuss this problem on the forums and with your friends. You must implement your own solution (do not share code), but feel free to share ideas.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PCA\n",
    "\n",
    "# def preprocess(X):\n",
    "#     m = X.shape[0]\n",
    "#     n = X.shape[1]\n",
    "    \n",
    "#     # Means.\n",
    "#     means = np.mean(X, axis=1)\n",
    "    \n",
    "#     # Abstracting means.\n",
    "#     means_tile = np.tile(means, (n, 1)).T\n",
    "#     biased_X = X - means_tile\n",
    "    \n",
    "#     # Infinity norms.\n",
    "#     norms = np.amax(np.abs(biased_X), axis=1)\n",
    "#     norms[np.argwhere(norms == 0)] = 1    \n",
    "#     norms_tile = np.tile(norms, (n, 1)).T\n",
    "#     stand_X = biased_X / norms_tile\n",
    "    \n",
    "#     return stand_X, means, norms\n",
    "\n",
    "# def eigen_decompose(X):\n",
    "#     # X: (m, n)\n",
    "#     stand_X, means, norms = preprocess(X)\n",
    "    \n",
    "#     # Get eigenvalue diagonal matrix.\n",
    "#     eig_val, eig_vec = np.linalg.eig(stand_X@stand_X.T)    # (m, m)\n",
    "#     D = np.diag(eig_val.real)\n",
    "\n",
    "#     C_norm = np.linalg.norm(eig_vec, axis=0)\n",
    "#     C_norm_tile = np.tile(C_norm.T, (C_norm.shape[0], 1))\n",
    "#     C = eig_vec / C_norm_tile\n",
    "\n",
    "#     return stand_X, means, norms, D, C\n",
    "\n",
    "\n",
    "# def reduce_dim(X, stand_X, k, C, D):\n",
    "    \n",
    "#     # Extract the eigenvalue from matrix D to calculate p.\n",
    "#     one_vec = np.ones(D.shape[0])\n",
    "#     eig_val = D@one_vec\n",
    "#     p = np.sum(eig_val[:k]) / np.sum(eig_val)\n",
    "#     print(eig_val)\n",
    "\n",
    "#     # Get the basis matrix B.\n",
    "#     C_k = np.zeros_like(C)\n",
    "#     C_k[:, :k] = C[:, :k]\n",
    "#     B_k = stand_X.T@C_k\n",
    "#     compressed_X = stand_X@B_k\n",
    "    \n",
    "#     return compressed_X, p\n",
    "\n",
    "# # stand_X, means, norms = preprocess(X)\n",
    "# # print(stand_X.shape)\n",
    "# # print(means.shape)\n",
    "# # print(norms.shape)\n",
    "# stand_X, means, norms, D, C = eigen_decompose(X)\n",
    "\n",
    "# k = 2\n",
    "# compressed_X, p = reduce_dim(X, stand_X, k, C, D)\n",
    "# print('Variance Captured:', int(p * 100), '%')\n",
    "# print(compressed_X.shape)\n",
    "# print(compressed_X[:5])\n",
    "# print(X[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression.\n",
    "\n",
    "def init_params(X, Z):\n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    k = Z.shape[1]\n",
    "    \n",
    "    theta = np.random.rand(n, k)\n",
    "    \n",
    "    return theta\n",
    "\n",
    "def sigmoid(a):\n",
    "    return 1.0 / (1.0+np.exp(-a))\n",
    "\n",
    "def loss(X, theta, Z):\n",
    "    m = Z.shape[0]    \n",
    "    sZ = sigmoid(X@theta) # (m, k)\n",
    "    \n",
    "    # Y: (m, k)\n",
    "    loss = np.mean(np.power(sZ-Z, 2), axis=0) / 2\n",
    "    \n",
    "    # Regularized items\n",
    "    garma = 1.0e-4\n",
    "    regularized_item = garma * np.mean(theta*theta, axis=0) / 2 # (k, 1)\n",
    "\n",
    "    loss += regularized_item\n",
    "    l = np.sum(loss)\n",
    "    \n",
    "    return l\n",
    "\n",
    "def gradient_update(X, theta, Z, lam):\n",
    "    theta_new = None\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # Regularized items\n",
    "    garma = 1.0e-4\n",
    "    grad = (-Z.T@X + theta.T@X.T@X).T / m + garma*theta\n",
    "        \n",
    "    theta_new = theta - lam*grad\n",
    "    \n",
    "    return theta_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, Z, lam=0.3, iterations=100):\n",
    "    theta = init_params(X, Z)\n",
    "    losses = np.zeros((iterations))\n",
    "\n",
    "    for i in range(iterations):\n",
    "        l = loss(X, theta, Z)\n",
    "        losses[i] = l\n",
    "        \n",
    "        theta = gradient_update(X, theta, Z, lam)\n",
    "    \n",
    "    return theta, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "theta, losses = gradient_descent(X, Z)\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02355028052263538\n"
     ]
    }
   ],
   "source": [
    "#CREATE ANY ADDITIONAL FUNCTIONS YOU WISH HERE\n",
    "\n",
    "def predict_Z(X, theta):\n",
    "    Z_prediction = np.zeros((X.shape[0], 2))\n",
    "    #YOUR CODE HERE\n",
    "\n",
    "    Z_prediction = X@theta\n",
    "    \n",
    "    return Z_prediction\n",
    "\n",
    "\n",
    "#Display Code. Leave it alooooooooooone.\n",
    "Z_prediction = predict_Z(X, theta)\n",
    "summed_error = np.sum((Z_prediction - Z).T@(Z_prediction - Z))\n",
    "print(summed_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
